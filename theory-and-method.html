<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Russian influence on Iźva Komi sibilant articulation</title>
  <meta name="description" content="Russian influence on Iźva Komi sibilant articulation">
  <meta name="generator" content="bookdown 0.3.16 and GitBook 2.6.7">

  <meta property="og:title" content="Russian influence on Iźva Komi sibilant articulation" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Russian influence on Iźva Komi sibilant articulation" />
  
  
  

<meta name="author" content="Niko Partanen">


<meta name="date" content="2017-04-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction.html">
<link rel="next" href="analysis.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i><b>1.1</b> Abstract</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#background"><i class="fa fa-check"></i><b>2.1</b> Background</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#multilinguality-as-a-resource"><i class="fa fa-check"></i><b>2.2</b> Multilinguality as a resource</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#transcription-system"><i class="fa fa-check"></i><b>2.3</b> Transcription system</a><ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#transcription-system"><i class="fa fa-check"></i><b>2.3.1</b> Transcription system used in this study</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#phenomena"><i class="fa fa-check"></i><b>2.4</b> Phenomena</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#research-questions"><i class="fa fa-check"></i><b>2.5</b> Research questions</a></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#data"><i class="fa fa-check"></i><b>2.6</b> Data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="introduction.html"><a href="introduction.html#open-issues-with-data"><i class="fa fa-check"></i><b>2.6.1</b> Open issues with data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory-and-method.html"><a href="theory-and-method.html"><i class="fa fa-check"></i><b>3</b> Theory and Method</a><ul>
<li class="chapter" data-level="3.1" data-path="theory-and-method.html"><a href="theory-and-method.html#theory"><i class="fa fa-check"></i><b>3.1</b> Theory</a></li>
<li class="chapter" data-level="3.2" data-path="theory-and-method.html"><a href="theory-and-method.html#methodological-implementation"><i class="fa fa-check"></i><b>3.2</b> Methodological implementation</a></li>
<li class="chapter" data-level="3.3" data-path="theory-and-method.html"><a href="theory-and-method.html#reproducibility"><i class="fa fa-check"></i><b>3.3</b> Reproducibility</a></li>
<li class="chapter" data-level="3.4" data-path="theory-and-method.html"><a href="theory-and-method.html#archiving"><i class="fa fa-check"></i><b>3.4</b> Archiving</a></li>
<li class="chapter" data-level="3.5" data-path="theory-and-method.html"><a href="theory-and-method.html#ELAN-model"><i class="fa fa-check"></i><b>3.5</b> ELAN annotations</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory-and-method.html"><a href="theory-and-method.html#caveouts-of-the-current-annotation-model"><i class="fa fa-check"></i><b>3.5.1</b> Caveouts of the current annotation model</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="theory-and-method.html"><a href="theory-and-method.html#automated-processing-with-r"><i class="fa fa-check"></i><b>3.6</b> Automated processing with R</a></li>
<li class="chapter" data-level="3.7" data-path="theory-and-method.html"><a href="theory-and-method.html#praat"><i class="fa fa-check"></i><b>3.7</b> Praat</a></li>
<li class="chapter" data-level="3.8" data-path="theory-and-method.html"><a href="theory-and-method.html#statistical-analysis"><i class="fa fa-check"></i><b>3.8</b> Statistical analysis</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>4</b> Analysis</a></li>
<li class="chapter" data-level="5" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>5</b> Conclusions</a><ul>
<li class="chapter" data-level="5.1" data-path="conclusions.html"><a href="conclusions.html#stable-variation-or-change-in-progress"><i class="fa fa-check"></i><b>5.1</b> Stable variation or change in progress</a></li>
<li class="chapter" data-level="5.2" data-path="conclusions.html"><a href="conclusions.html#variation-of-variable"><i class="fa fa-check"></i><b>5.2</b> Variation of variable</a></li>
<li class="chapter" data-level="5.3" data-path="conclusions.html"><a href="conclusions.html#comparable-case-studies"><i class="fa fa-check"></i><b>5.3</b> Comparable case studies</a><ul>
<li class="chapter" data-level="5.3.1" data-path="conclusions.html"><a href="conclusions.html#final-sibilant-deletion-in-brazilian-portuguese"><i class="fa fa-check"></i><b>5.3.1</b> Final sibilant deletion in Brazilian Portuguese</a></li>
<li class="chapter" data-level="5.3.2" data-path="conclusions.html"><a href="conclusions.html#salvadoran-spanish--s-deletion-and-aspiration"><i class="fa fa-check"></i><b>5.3.2</b> Salvadoran Spanish -s deletion and aspiration</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="technical-documentation.html"><a href="technical-documentation.html"><i class="fa fa-check"></i><b>6</b> Technical documentation</a><ul>
<li class="chapter" data-level="6.1" data-path="technical-documentation.html"><a href="technical-documentation.html#code"><i class="fa fa-check"></i><b>6.1</b> Code</a></li>
<li class="chapter" data-level="6.2" data-path="technical-documentation.html"><a href="technical-documentation.html#conversion-patterns"><i class="fa fa-check"></i><b>6.2</b> Conversion patterns</a></li>
<li class="chapter" data-level="6.3" data-path="technical-documentation.html"><a href="technical-documentation.html#functions"><i class="fa fa-check"></i><b>6.3</b> Functions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="technical-documentation.html"><a href="technical-documentation.html#sle2016partanentransliterate"><i class="fa fa-check"></i><b>6.3.1</b> sle2016partanen::transliterate</a></li>
<li class="chapter" data-level="6.3.2" data-path="technical-documentation.html"><a href="technical-documentation.html#sle2016partanensib_tier_cyr2ipa"><i class="fa fa-check"></i><b>6.3.2</b> sle2016partanen::sib_tier_cyr2ipa</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="technical-documentation.html"><a href="technical-documentation.html#nice-spectrograms"><i class="fa fa-check"></i><b>6.4</b> Nice spectrograms</a></li>
<li class="chapter" data-level="6.5" data-path="technical-documentation.html"><a href="technical-documentation.html#manual-tasks"><i class="fa fa-check"></i><b>6.5</b> Manual tasks</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Russian influence on Iźva Komi sibilant articulation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="theory-and-method" class="section level1">
<h1><span class="header-section-number">Section 3</span> Theory and Method</h1>
<div id="theory" class="section level2">
<h2><span class="header-section-number">3.1</span> Theory</h2>
<p>My study falls within variationist sociolinguistics, and the variable under investigation is a simple phonetic variable with two discrete variants. In no context the absence of the sound can be a variable, so it is possible to traverse from phonological transcription to individual occurrences. However, one could argue that the dataset used is not entirely traditional. Language documentation goals are generally described as striving to create a multipurpose data, but at the same time the target is also descriptive and aims to produce relatively standard grammars and lexical resources. In this sense studying the variation with more sociolinguistic toolkit can be seen as somewhat non-standard use of language documentation data and also contributes to the idea of multipurpose data.</p>
<p>However, there are some issues related to the fact that data has not been gathered as a resource for variational study.</p>
<p>I’ve tried to keep the analysis section very uncomplicated, although there are issues which have been dealt with as they have become apparent.</p>
<ul>
<li>Should the names be included in the analysis? Some are truly ambivalent and are pronounced quite identically in both languages, at least to the degree that there are no phonemes which would demand radical amount of adaptation (yes, the stress still differs)</li>
<li>What to do with ubiguous forms like сет? Current solution: leave them out (сила, сет)</li>
<li>What all has to be resolved due the multilingualism of the dataset (even small amount of Nenets within Komi)</li>
</ul>
<p>There are two annotated variants and all occurrences in the corpus are taken into account, although the more standard Komi pronunciation is overwhelmingly the most common in data. I have not found occurrences where the realization of the variable could be zero, so I’m quite confident I’ve captured all occurrences in my annotations. I have described the procedure how variables are selected in section <a href="theory-and-method.html#ELAN-model">3.5</a> about ELAN annotations. It is also assumed that these variants are functionally equivalent, so that there are no obvious differences in meaning. This variable is also good for investigation as it is very common – palatal sibilants are very typical phonemes in the Permic languages and thereby occur in all recordings. The choice of variable was very much influenced by the procedure described by Tagliamonte <span class="citation">(<a href="#ref-tagliamonte2006a">2006</a>, 70-)</span>. However, in the initial stage of the study it was clear to me that there is something going on with the sibilants, it was only after later analysis of the data during which I started to understand different variables which seem to be interacting here.</p>
<p>Parts of the region studied are under the influence of Komi written standard, but in the peripheric regions Komi is not widely teached, and if it is, the variety is often the local dialect. This has impact to how conscious the individuals are about the norms of the standard language <span class="citation">(Milroy and Milroy <a href="#ref-milroyEtAl1997a">1997</a>, 75)</span> <!-- Note to self: double check this article for more -->. There have been earlier reports about the spread of standard language variants within Komi Republic, especially within lexical items. However, Cypanov also mentions his observations how also at the Komi countryside the standard language would be connected to the speakers’ educational level, but at the same time in some regions (Luza, Udora and Iźva being listed as examples) the local dialects also compete with the literary standard in their value and authority. <span class="citation">(Tsypanov <a href="#ref-cypanov2009a">2009</a>, 215)</span>. <!-- This sounds exactly like the process described by Milroys where 'vernacular maintenance' competes with the standard [other Milroy, add to bibliography p. 53].-->So the institutional endorsement of standard is present for some local varieties only, which is salient in the sense that also the local dialect embracement can be seen as a reaction to the standardization demands. If it is a counterreaction, it may not be similarly present in the areas where the original catalyst for it is missing.</p>
<p>It must also be taken into account that the variation within endangered language may not be entirely as expected from larger languages. Lyle Campbell has even recently suggested that the variation within endangered languages may not even be regular <span class="citation">(Campbell <a href="#ref-campbell-l2016a">2016</a>, 257–59)</span>. Campbell gives examples from several languages, and it seems clear that for example the variation in the speech of semi-speakers may not fit any regular pattern. The process likely has something to do with the fragmentation of community which seems to be taking places in many language endangerment situations. We wrote recently about this with Janne Saarikivi <span class="citation">(Partanen and Saarikivi <a href="#ref-partanenEtAl2016a">2016</a>)</span>, and our investigation of the social networks in a fixed neighbourhood shows clearly that the assumptions of who is Karelian speaker are getting very detached from the actual reality of who would be a speaker, and the language ends up being used in very closed and heterogenous groups which are not aware about each others. The language acquisition and use takes place in these micro-networks within the larger community, which makes it not surprising if the patterns in speech are not very logical community wide. Maybe instead of irregularity the factors influencing the language use have just became too complex and fragmented to be easily studied? Already some fifteen years ago Heikki Paunonen has commented that <em>“overflowing variation is a sign of crisis in the language community”</em> <span class="citation">(Paunonen <a href="#ref-paunonen2000a">2000</a>)</span>, and probably one could trace down more comments along these lines in the literature.</p>
<p>However, generally speaking one could say that small endangered languages are kind of treasure troves on which one can use the methods of variationistic studies. It is not uncommon that different grammars and list variables and phenomena which are in free variation.</p>
</div>
<div id="methodological-implementation" class="section level2">
<h2><span class="header-section-number">3.2</span> Methodological implementation</h2>
<p>Methodology always has two aspects – scientific and technical. Milroy and Gordon pose the following question <span class="citation">(Milroy and Gordon <a href="#ref-milroyEtAl2003a">2003</a>, 136)</span>:</p>
<blockquote>
<p>How did the investigators proceed from having hours of tape-recorded speech to reporting the numbers in the tables?</p>
</blockquote>
<p>I think in what it comes to data archiving and automatization of different work phases we start to be in the point where the connection between the raw data and the resulting analysis should be entirely seamless.</p>
<p>In principle the ideal technical framework would allow us to focus only to the scientific side, as that is where the linguistic questions are being formulated and solved. However, although there are many branches of linguistics which do not demand concrete access to the data, it is also very common and sound to base the conclusions into actual occurrences of something somewhere. While dealing with the annotation layers to work with, in practice we almost inevitably have to settle to something that is not perfect, but allows us to get the work done. I’m personally quite strict with this, and having some programming background, I’m very reluctant to get into manual labour which I see computer could perform better, faster and more reliably. However, I think it is very important to identify what are those parts where manual labour is needed and valuable, and built the workflow so that the possible manual strain would be on exactly those sections where human input matters.</p>
<p>There are many workflows surrounding sociolinguistic data, for example, one suggested by Nagy and Meierhof <span class="citation">(<a href="#ref-nagyEtAl2015a">2015</a>)</span>. I’m suggesting something very much in that strain, but with the difference that this model is, as I see it, more reliable and easy to maintain. The workflow they describe is still very much centered with exporting files, whereas I would see this as most of the time unnecessary step, since the data we want to deal with is already very well presented in the files we have in the beginning. Parsing this data directly to our analysis has the benefit that the changes in data are immediately present in the further results.</p>
<p>In many ways it is often possible to imagine ideal workflow. However, as important as this is, one also has to realize the limitations which may make this unrealistic. A very common issue is that the current tools we have do not allow fast enough annotation if the annotations have to be fit into a very byzantine and complex data structures. Also the problem tends to arise that even though creating annotations now would work, there can be some problems which occur later when the annotations are edited, realigned and corrected.</p>
<p>It is possible to delineate following principles:</p>
<ul>
<li>One piece of information should be written only once</li>
<li>Data should be interconnected in the way that relations between different units can be reconstructed (this doesn’t need to be simple or straightforward, but these relations have to exist one way or another in machine readable format. More the connections are documented, the better.)</li>
<li>Working with annotations should be relatively rapid and effortless</li>
</ul>
<p>In reality one has to balance between these principles. Of course one could argue that the last one is easiest to cut from, but the case is not so straightforward, as it has direct impact to the working hours spent which eventually comes into the number of occurrences in the corpus. This is especially important if more statistical methods are employed, for which it may be reasonable to have several parallel datasets used for testing different hypotheses. If data editing is extremely tedious, then it becomes much less feasible that the data is treated as would be the most suitable. And all this kind of boils down to the fact:</p>
<ul>
<li>There has to be a long-term data curation plan where these study-specific annotations fit</li>
</ul>
<p>Even though some annotations would be done just for one study, there is no reason they should be separated from the rest of the corpus. However, they should be added to the corpus in a way which doesn’t demand extra work from normal data curation. This means that they should not be too fixed to the current values, for example, they should not assume that elements such as tokens are immutable. This would be the case if annotations would be stored externally from the corpus itself, for example, in Praat files or eventually on spreadsheets. For these reasons I have decided to store the annotations as part of the corpus itself.</p>
</div>
<div id="reproducibility" class="section level2">
<h2><span class="header-section-number">3.3</span> Reproducibility</h2>
<p>By saying that my study is reproduceable I do not claim that my results are necessarily correct. I only mean that the others can verify what I have done and evaluate it with the data I have used. Ideally the study results would be repeated with a different dataset, which would in many ways be actually desired, since that would immediately add credibility to my ideas presented here. As reproducibility is a rather new concept in linguistic sciences, there seems to be quite a bit of confusion over the terms <strong>reproduction</strong>, <strong>replication</strong> and <strong>independent verification</strong>. Biostatistician Roger Peng has written very clearly about this in <a href="http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/">Simply Statistics blog</a> <span class="citation">(Peng <a href="#ref-peng2014a">2014</a>)</span>.</p>
<p>The study follows logic not particularly unusual for a scientific study: a phenomena has been observed and found interesting after further contextualization. A further study was planned in order to find out what it is about, so a corpus sample has been selected and annotated. These annotations are analyzed and the results are interpreted against the ideas that arose after the initial observation and contextualisation. The analysis part is mainly within the <a href="conclusions.html#conclusions">5</a> Conclusions section of this study.</p>
</div>
<div id="archiving" class="section level2">
<h2><span class="header-section-number">3.4</span> Archiving</h2>
<p>The corpus files are archived in The Language Archive of Nijmegen Max Planck institute. They are organized under the node <strong>Permic_Varieties/kpv/</strong>. In the archive structure all sessions are treated as entities on same hierarchy level. This may seem confusing, but the idea is that one has to consult metadata in order to know into which project and working group which session is connected. It would had been customary to organize data by <strong>academic projects</strong>. However, this model becomes problematic when the same data has been collected, transcribed, digitalized, reanalyzed and archived by totally disconnected people often many decades apart from one another. Thereby the only model to arrange these files in an honest manner is to list in metadata all relevant actors and projects involved.</p>
<p>In the archive there has been an attempt to maintain rough dialect division, so that the files would be named by prefixes marking different varieties. This is also complicated topic, as same recording contains often data from speakers of different dialects. Individual speakers have often been very mobile, so they also can have mixed features in their everyday speech. As many other good ideas, also this dialect based file naming has been somewhat futile.</p>
<p>The subcorpus used in this study today, 2017-04-13, may not be connected to those files the archive contains in whatever future date this study is being read. However, this study refers explicitly to those file versions which were valid and accessible at the time when this document was compiled.</p>
</div>
<div id="ELAN-model" class="section level2">
<h2><span class="header-section-number">3.5</span> ELAN annotations</h2>
<p>The ELAN annotation model used in the corpus is relatively simple, the data being set on different layers which correspond to specific time-aligned utterances. This means that for one Komi utterance there are often different data layers, for example, Russian translation, English translation or comments. Also tokenized data layer is provided, but the tokenized units are not connected to the recording itself.</p>
<p>For this study a new layer is added on which the tokens containing sibilants are time aligned and transcribed in IPA. This has been done by copying the token containing tier, filtering out the tokens which do not contain palatal sibilants and time aligning the remaining word forms.</p>
<p>The steps taken have been:</p>
<ul>
<li>Copying tier of symbolic subdivision type which contains the tokens into tier of included in type</li>
<li>Filtering the sibilant containt forms with regular expression <code>^((?!зь)(?!зё)(?!зя)(?!зю)(?!зи)(?!зе)(?!сь)(?!сё)(?!ся)(?!сю)(?!си)(?!се)(?!Зь)(?!Зё)(?!Зя)(?!Зю)(?!Зи)(?!Зе)(?!Сь)(?!Сё)(?!Ся)(?!Сю)(?!Си)(?!Се)(?!тс)(?!ст)(?!Ст)(?!щ)(?!Щ).)*$</code>, which selects everything that can’t contain a feature I am interested, and replacing it’s result with an empty string</li>
<li>Using ELAN’s <strong>Remove annotations or values</strong> tool to remove all annotations on this tier when they contain an empty annotation</li>
</ul>
<p>With this workflow we get from this:</p>
<div class="figure">
<img src="figures/elan1.png" alt="Elan file in the original state" />
<p class="caption">Elan file in the original state</p>
</div>
<p>To this, which can relatively easily be time aligned one by one:</p>
<div class="figure">
<img src="figures/elan2.png" alt="Added sib-tier with only sibilants left" />
<p class="caption">Added sib-tier with only sibilants left</p>
</div>
<p>The transcription system used is described in section <a href="introduction.html#transcription-system">2.3</a>. about transcription systems.</p>
<p>This means that an utterance:</p>
<p>Would eventually be transcribed on the sibilant annotation tier as:</p>
<blockquote>
<p>mijanɨɕ / миянсьым (optional) / 6</p>
</blockquote>
<p>This is not a perfect method, but the best I was able to come up within the rationale and limitations explained above. Now this line contains following pieces of information: <strong>IPA transcription on phonetic level</strong>, <strong>proposed Cyrillic transcription – this may differ from what is on the transcription tier at the moment, but comparison will be done later</strong>, <strong>tokenized unit we are dealing with on the current reference id</strong>. The segment is time-aligned manually and while doing that the position within utterance is counted. There is some space for automation here, but it is still relatively easy to spot later when there have been mistakes, and adding token number manually is an easy to see which annotations have been listened through already.</p>
<p>I’m sure one of the first criticues would be why I don’t store these pieces of information on different tiers. The reason is simple: I don’t want to maintain a mess like that. It would also increase the size of the ELAN file very much. I agree that the ideal way to represent data like this would be to store each piece of information separatedly, but my counter-argument is that the data as it is now can be easily transformed into such a tidy format. As always, the way we store the data doesn’t dictate in which form we use or analyze it. It might limit that though, and that is something we should of course try to avoid. This is also the reason why there is so much extra hocus-pocus on this tier. I want to make sure the transformation is painless.</p>
<p>All the current annotation model does is to say:</p>
<blockquote>
<p>This is the IPA transcription of the n:th element on this annotation unit in which we currently are, as was in the Git revision whatever. And by the way, for some tokens one could propose a better way to write them phonemically, but we don’t need to hurry with that.</p>
</blockquote>
<p>This solves several practical problems:</p>
<ul>
<li>How to make semi-independent annotations which are still somehow connected to the dependent annotations?</li>
<li>How to make sure the later changes on the other tiers do not mess up the system</li>
</ul>
<p>Now there is still quite much manual work in translitteration to phonemic IPA, aligning everything and identifying the necessary phonetic adjustments. Thereby I wrote a small function which does the transliteration. The screenshot below illustrates the changes it does inside ELAN file:</p>
<div class="figure">
<img src="figures/elan_ipa_diff.png" alt="Sibilant tier before and after running sle2016partanen::sib_tier_cyr2ipa function" />
<p class="caption">Sibilant tier before and after running sle2016partanen::sib_tier_cyr2ipa function</p>
</div>
<p>After this each token on sibilant tier is manually aligned and evaluated. This is relatively time consuming phase, but in many ways it is also the most important one. The whole study is in the end about these variables, so spending most of the time with analysing them is indeed quite appropriate. What I’ve tried to reach in this workflow is state where minimal amount of time is spent in rather unimportant manual tasks, and thereby what really matters gets the time it deserves. In the end automated workflow also makes it possible to reach relatively large sample within the current time frame. Although time is not really the most pressing issue, our daily working hours are in the end always limited.</p>
<div id="caveouts-of-the-current-annotation-model" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Caveouts of the current annotation model</h3>
<p>The problem with the current model is that it is pretty manual and the annotated sibilant containing forms are not strictly connected to the corresponding tokens within the utterances. The main reason to this is that I want the sibilant annotated tokens to remain independent from further changes in the main transcription.</p>
<p>It is also somewhat problematic that the actual annotation is usually done in a longer time span and the exact method may be refined. For example, one may realize later a context which should had been taken into account in the regular expression. This leads to a change which is automatically implemented in the further files, but must be manually carried out in older files. This is not a huge problem in itself, but it means that the workflow is easily not as reproduceable and automatic as it may seem.</p>
</div>
</div>
<div id="automated-processing-with-r" class="section level2">
<h2><span class="header-section-number">3.6</span> Automated processing with R</h2>
<p>In order to retrieve the sibilant information from ELAN files an R package <code>FRelan</code> is used. It contains several functions for parsing data from ELAN files to a data frame, which is an R internal tabular format which works rather well for data like this. Each token forms its own row. This data frame is merged with metadata which contains biographical and geographical information about, for example, about the speakers themselves and the time and place related information about the context where the utterance was recorded.</p>
<p>The variables relevant for my analysis are:</p>
<ul>
<li>Age of the speaker</li>
<li>Birthplace of the speaker</li>
<li>Place of residence of the speaker</li>
<li>Recording time</li>
<li>Recording setting (formal, informal)</li>
<li>Education of the speaker</li>
</ul>
<p>These variables are compared to the frequency of different sibilant allophones.</p>
</div>
<div id="praat" class="section level2">
<h2><span class="header-section-number">3.7</span> Praat</h2>
<p>Most of the time the distinction between these allophones is relatively easy to hear. However, I have used Praat in many cases to establish the baseline for these features, and also to validate whether some cases are as complex as they sound like.</p>
</div>
<div id="statistical-analysis" class="section level2">
<h2><span class="header-section-number">3.8</span> Statistical analysis</h2>
<p>Statistical methods have not been widely employed within Uralic studies, although sociolinguistics has been practised in different forms. However, for whatever reasons variationistic studies have not been very common. There are naturally exceptions, for example Niina Kunnas’s study of word final vowels in Karelian <span class="citation">(Kunnas <a href="#ref-kunnas2007a">2007</a>)</span> falls comfortably to this framework. Within wider perspective of sociolinguistics Sali Tagliamonte gives quite nice overview in her recent book <span class="citation">(<a href="#ref-tagliamonte2016a">2016</a>, 107)</span> about the history of statistical methods on this field. She refers to her interview with David Sankoff, with the observation that within sociolinguistics the data generally tends to be messier and more complicated than on many other scientific fields where statistical methods are regularly employed. Later the discussion turns into the fact how ultimately one has to be familiar with the dataset used, and I also However, inevitable conclusion is that one has to employ some statistical tools in order to verify, and also often to find, the patterns in the data.</p>
<p>While discussing the use of statistical tools with different researchers one gets often impression that there is not always that clear idea about their use. This is very understandable. As I mentioned, the statistics have not been used that much in Uralistics. However, they are often demanded by reviewers or scientific boards. I’ve heard countless of anecdotes about situations where the statistical tests just have been made because they have to be made. On the other hand, one finds at times something that could be described as blind faith in statistics. Small data, stange ideas – no problems, just make the calculations (or let computer do them).</p>
<p>I’m just trying to navigate in these waters myself and to find my own position. As far as I see it, the statistics kind of inevitably come into play when we want to make claims about numeric occurrences of something somewhere. The patterns and frequencies aren’t something we can outline just by looking into data, especially when the amount of data starts to be big enough. Statistics can often tell us whether something really occurs, but they don’t do very much to explain <em>what does it mean</em> or <em>why does it happen</em>. However, the latter questions are also impossible to answer before it is ascertained that the feature is actually there and it has some pattern.</p>
<p>The variable I’m investigating fits well into this framework, as there is part of the variation which seems to pattern easily with very traditional statistical tests. One pattern like this is geography. However, in order to contextualize the occurrences better one has to look into the ideologies, stylistic practises and individual agency of the speaker, which sets the study more into the the third wave of sociolinguistic research outlined recently by Eckert <span class="citation">(<a href="#ref-eckert2012a">2012</a>)</span>.</p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-tagliamonte2006a">
<p>Tagliamonte, Sali A. 2006. <em>Analysing Sociolinguistic Variation</em>. Key Topics in Sociolinguistics. Cambridge University Press.</p>
</div>
<div id="ref-milroyEtAl1997a">
<p>Milroy, James, and Lesley Milroy. 1997. “Exploring the Social Constraints on Language Change: Essays in Memory of Einar Haugen.” In <em>Language and Its Ecology</em>, 75–101. Trends in Linguistics. Studies and Monographs 100. Mouton de Gruyter.</p>
</div>
<div id="ref-cypanov2009a">
<p>Tsypanov, Jevgeni. 2009. “Permiläisten Kielten Nykytila.” In <em>The Quasquicentennial of the Finno-Ugrian Society</em>, edited by Jussi Ylikoski, 207–44. Suomalais-Ugrilaisen Seuran Toimituksia 258. Helsinki: Suomalais-Ugrilainen Seura.</p>
</div>
<div id="ref-campbell-l2016a">
<p>Campbell, Lyle. 2016. “Language Documentation and Historical Linguistics: Studies in Honor of Marianne Mithun.” In <em>Language Contact and Change in Americas</em>, edited by Andrea Berez-Kroeker, Diane M. Hinz, and Carmen Jany, 249–73. John Benjamins Publishing Company.</p>
</div>
<div id="ref-partanenEtAl2016a">
<p>Partanen, Niko, and Janne Saarikivi. 2016. “Fragmentation of the Karelian Language and Its Community: Growing Variation at the Threshold of Language Shift: New and Old Language Diversities.” In <em>Linguistic Genocide or Superdiversity</em>, edited by Reetta Toivanen and Janne Saarikivi, 0–0. Multilingual Matters.</p>
</div>
<div id="ref-paunonen2000a">
<p>Paunonen, Heikki. 2000. “Suomen Kielen Morfologisista Muutosmekanismeista.” In <em>Muotojen Mieli. Kirjoituksia Morfologiasta Ja Variaatiosta</em>, edited by Lea Laitinen, Hanna Lappalainen, Päivi Markkola, and Johanna Vaattovaara, 187–248. Kieli 5. Helsingin yliopiston suomen kielen laitos.</p>
</div>
<div id="ref-milroyEtAl2003a">
<p>Milroy, Lesley, and Matthew Gordon. 2003. <em>Sociolinguistics: Method and Interpretation</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-nagyEtAl2015a">
<p>Nagy, Naomi, and Miriam Meyerhoff. 2015. “Extending ELAN into Variationist Sociolinguistics.” <em>Linguistics Vanguard</em> 1 (1): 271–81. doi:<a href="https://doi.org/DOI 10.1515/lingvan-2015-001">DOI 10.1515/lingvan-2015-001</a>.</p>
</div>
<div id="ref-peng2014a">
<p>Peng, Roger. 2014. “The Real Reason Reproducible Research Is Important.” <a href="http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/" class="uri">http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/</a>.</p>
</div>
<div id="ref-kunnas2007a">
<p>Kunnas, Niina. 2007. “Miten Muuttuu Runokylien Kieli: Reaaliaikatutkimus Jälkitavujen a-Loppuisten Vokaalijonojen Variaatiosta Vienalaismurteissa.” PhD thesis, Humanistinen tiedekunta, Suomen kielen, informaationtutkimuksen ja logopedian laitos, Oulun yliopisto.</p>
</div>
<div id="ref-tagliamonte2016a">
<p>Tagliamonte, Sali A. 2016. <em>Making Waves: The Story of Variationist Sociolinguistics</em>. Wiley Blackwell.</p>
</div>
<div id="ref-eckert2012a">
<p>Eckert, Penelope. 2012. “Three Waves of Variation Study: The Emergence of Meaning in the Study of Sociolinguistic Variation.” <em>Annual Review of Anthropology</em> 41. Annual Reviews: 87–100.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/nikopartanen/sle2016partanenblob/master/02-methodology.rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
