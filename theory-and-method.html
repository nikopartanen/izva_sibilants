<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Russian influence on Iźva Komi sibilant articulation</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Russian influence on Iźva Komi sibilant articulation">
  <meta name="generator" content="bookdown 0.0.71 and GitBook 2.6.7">

  <meta property="og:title" content="Russian influence on Iźva Komi sibilant articulation" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Russian influence on Iźva Komi sibilant articulation" />
  
  
  

<meta name="author" content="Niko Partanen">

<meta name="date" content="2016-05-28">


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction.html">
<link rel="next" href="conclusions.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i><b>1.1</b> Abstract</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#about-using-github-pages"><i class="fa fa-check"></i><b>1.2</b> About using GitHub pages</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#transcription-system"><i class="fa fa-check"></i><b>2.1</b> Transcription system</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#transcription-system"><i class="fa fa-check"></i><b>2.1.1</b> Transcription system used in this study</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#phenomena"><i class="fa fa-check"></i><b>2.2</b> Phenomena</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#research-questions"><i class="fa fa-check"></i><b>2.3</b> Research questions</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#data"><i class="fa fa-check"></i><b>2.4</b> Data</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#open-issues-with-data"><i class="fa fa-check"></i><b>2.4.1</b> Open issues with data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory-and-method.html"><a href="theory-and-method.html"><i class="fa fa-check"></i><b>3</b> Theory and Method</a><ul>
<li class="chapter" data-level="3.1" data-path="theory-and-method.html"><a href="theory-and-method.html#theory"><i class="fa fa-check"></i><b>3.1</b> Theory</a></li>
<li class="chapter" data-level="3.2" data-path="theory-and-method.html"><a href="theory-and-method.html#methodological-implementation"><i class="fa fa-check"></i><b>3.2</b> Methodological implementation</a></li>
<li class="chapter" data-level="3.3" data-path="theory-and-method.html"><a href="theory-and-method.html#reproducibility"><i class="fa fa-check"></i><b>3.3</b> Reproducibility</a></li>
<li class="chapter" data-level="3.4" data-path="theory-and-method.html"><a href="theory-and-method.html#archiving"><i class="fa fa-check"></i><b>3.4</b> Archiving</a></li>
<li class="chapter" data-level="3.5" data-path="theory-and-method.html"><a href="theory-and-method.html#ELAN-model"><i class="fa fa-check"></i><b>3.5</b> ELAN annotations</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory-and-method.html"><a href="theory-and-method.html#caveouts-of-the-current-annotation-model"><i class="fa fa-check"></i><b>3.5.1</b> Caveouts of the current annotation model</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="theory-and-method.html"><a href="theory-and-method.html#automated-processing-with-r"><i class="fa fa-check"></i><b>3.6</b> Automated processing with R</a></li>
<li class="chapter" data-level="3.7" data-path="theory-and-method.html"><a href="theory-and-method.html#praat"><i class="fa fa-check"></i><b>3.7</b> Praat</a></li>
<li class="chapter" data-level="3.8" data-path="theory-and-method.html"><a href="theory-and-method.html#statistical-analysis"><i class="fa fa-check"></i><b>3.8</b> Statistical analysis</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>4</b> Conclusions</a><ul>
<li class="chapter" data-level="4.1" data-path="conclusions.html"><a href="conclusions.html#stable-variation-or-change-in-progress"><i class="fa fa-check"></i><b>4.1</b> Stable variation or change in progress</a></li>
<li class="chapter" data-level="4.2" data-path="conclusions.html"><a href="conclusions.html#variation-of-variable"><i class="fa fa-check"></i><b>4.2</b> Variation of variable</a></li>
<li class="chapter" data-level="4.3" data-path="conclusions.html"><a href="conclusions.html#comparable-case-studies"><i class="fa fa-check"></i><b>4.3</b> Comparable case studies</a><ul>
<li class="chapter" data-level="4.3.1" data-path="conclusions.html"><a href="conclusions.html#final-sibilant-deletion-in-brazilian-portuguese"><i class="fa fa-check"></i><b>4.3.1</b> Final sibilant deletion in Brazilian Portuguese</a></li>
<li class="chapter" data-level="4.3.2" data-path="conclusions.html"><a href="conclusions.html#salvadoran-spanish--s-deletion-and-aspiration"><i class="fa fa-check"></i><b>4.3.2</b> Salvadoran Spanish -s deletion and aspiration</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="technical-documentation.html"><a href="technical-documentation.html"><i class="fa fa-check"></i><b>5</b> Technical documentation</a><ul>
<li class="chapter" data-level="5.1" data-path="technical-documentation.html"><a href="technical-documentation.html#code"><i class="fa fa-check"></i><b>5.1</b> Code</a></li>
<li class="chapter" data-level="5.2" data-path="technical-documentation.html"><a href="technical-documentation.html#conversion-patterns"><i class="fa fa-check"></i><b>5.2</b> Conversion patterns</a></li>
<li class="chapter" data-level="5.3" data-path="technical-documentation.html"><a href="technical-documentation.html#functions"><i class="fa fa-check"></i><b>5.3</b> Functions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="technical-documentation.html"><a href="technical-documentation.html#sle2016partanentransliterate"><i class="fa fa-check"></i><b>5.3.1</b> sle2016partanen::transliterate</a></li>
<li class="chapter" data-level="5.3.2" data-path="technical-documentation.html"><a href="technical-documentation.html#sle2016partanensib_tier_cyr2ipa"><i class="fa fa-check"></i><b>5.3.2</b> sle2016partanen::sib_tier_cyr2ipa</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="technical-documentation.html"><a href="technical-documentation.html#manual-tasks"><i class="fa fa-check"></i><b>5.4</b> Manual tasks</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>6</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Russian influence on Iźva Komi sibilant articulation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="theory-and-method" class="section level1">
<h1><span class="header-section-number">Section 3</span> Theory and Method</h1>
<div id="theory" class="section level2">
<h2><span class="header-section-number">3.1</span> Theory</h2>
<p>My study falls within variationist sociolinguistics, and the variable under investigation is very traditional as it is phonetical. I’ve tried to keep the analysis section very uncomplicated, especially since I’m rather new on this field. There are two annotated variants and all occurrences in the corpus are taken into account, although the more standard Komi pronunciation is overwhelmingly the most common in data. I have not found occurrences where the realization of the variable could be zero, so I’m quite confident I’ve captured all occurrences in my annotations. I have described the procedure how variables are selected in section <a href="theory-and-method.html#ELAN-model">3.5</a> about ELAN annotations. It is also assumed that these variants are functionally equivalent, so that there are no obvious differences in meaning. This variable is also good for investigation as it is very common – palatal sibilants are very typical phonemes in the Permic languages and thereby occur in basically any text. The choice of variable was very much influenced by the procedure described by Tagliamonte <span class="citation">(Tagliamonte <a href="#ref-tagliamonte2006a">2006</a>, 70-)</span></p>
<p>Parts of the region studied are under the influence of Komi written standard, but in the peripheric regions Komi is not widely teached, and if it is, the variety is often the local dialect. This has impact to how conscious the individuals are about the norms of the standard language <span class="citation">(Milroy and Milroy <a href="#ref-milroyEtAl1997a">1997</a>, 75)</span> <!-- Note to self: double check this article for more -->. There have been earlier reports about the spread of standard language variants within Komi Republic, especially within lexical items. However, Cypanov also mentions his observations how also at the Komi countryside the standard language would be connected to the speakers’ educational level, but at the same time in some regions (Luza, Udora and Iźva being listed as examples) the local dialects also compete with the literary standard in their value and authority. <span class="citation">(Tsypanov <a href="#ref-cypanov2009a">2009</a>, 215)</span>. <!-- This sounds exactly like the process described by Milroys where 'vernacular maintenance' competes with the standard [other Milroy, add to bibliography p. 53].-->So the institutional endorsement of standard is present for some local varieties only, which is salient in the sense that also the local dialect embracement can be seen as a reaction to the standardization demands. If it is a counterreaction, it may not be similarly present in the areas where the original catalyst for it is missing.</p>
<p>It must also be taken into account that the variation within endangered language may not be entirely as expected from larger languages. Lyle Campbell has even recently suggested that the variation within endangered languages may not even be regular <span class="citation">(Campbell <a href="#ref-campbell-l2016a">2016</a>, 257–59)</span>. Campbell gives examples from several languages, and it seems clear that for example the variation in the speech of semi-speakers may not fit any regular pattern. The process likely has something to do with the fragmentation of community which seems to be taking places in many language endangerment situations. We wrote recently about this with Janne Saarikivi <span class="citation">(Partanen and Saarikivi <a href="#ref-partanenEtAl2016a">2016</a>)</span>, and our investigation of the social networks in a fixed neighbourhood shows clearly that the assumptions of who is Karelian speaker are getting very detached from the actual reality of who would be a speaker, and the language ends up being used in very closed and heterogenous groups which are not aware about each others. The language acquisition and use takes place in these micro-networks within the larger community, which makes it not surprising if the patterns in speech are not very logical community wide. Maybe instead of irregularity the factors influencing the language use have just became too complex and fragmented to be easily studied? Already some fifteen years ago Heikki Paunonen has commented that <em>“overflowing variation is a sign of crisis in the language community”</em> <span class="citation">(Paunonen <a href="#ref-paunonen2000a">2000</a>)</span>, and probably one could trace down more comments along these lines in the literature.</p>
</div>
<div id="methodological-implementation" class="section level2">
<h2><span class="header-section-number">3.2</span> Methodological implementation</h2>
<p>Methodology always has two aspects – scientific and technical. The first is about what do we want to do, and the latter deals with how do we do it. In principle the ideal technical framework would allow us to focus only to the scientific side, as that is where the linguistic questions are being formulated and solved. However, although in principle there are many branches of linguistics which do not demand concrete access to the data, it is also very common and sound to base the conclusions into actual occurrences of something somewhere. While dealing with the annotation layers to work with, in practice we almost inevitably have to settle to something that is not perfect, but allows us to get the work done. I’m personally quite strict with this, and having some programming background, I’m very reluctant to get into manual labour which I see computer could perform better, faster and more reliably. However, I think it is very important to identify what are those parts where manual labour is needed and valuable, and built the workflow so that the possible manual strain would be on exactly those sections where human input matters.</p>
<p>There are many workflows surrounding sociolinguistic data, for example, one suggested by Nagy and Meierhof <span class="citation">(Nagy and Meyerhoff <a href="#ref-nagyEtAl2015a">2015</a>)</span>. I’m suggesting something very much in that strain, but with the difference that this model is, as I see it, more reliable and easy to maintain. The workflow they describe is still very much centered with exporting files, whereas I would see this as most of the time unnecessary step, since the data we want to deal with is already very well presented in the files we have in the beginning. Parsing this data directly to our analysis has the benefit that the changes in data is immediately represented in the further results.</p>
<p>In many ways it is often possible to imagine ideal workflow. However, as important as this is, one also has to realize the limitations which may make this unrealistic. A very common issue is that the current tools we have do not allow fast enough annotation if the annotations have to be fit into a very byzantine and complex data structures. Also the problem tends to arise that even though creating annotations now would work, there can be some problems which occur later when the annotations are edited, realigned and corrected.</p>
<p>It is possible to delineate following principles:</p>
<ul>
<li>One piece of information should be written only once</li>
<li>Data should be interconnected in the way that relations between different units can be reconstructed (this doesn’t need to be simple or straightforward, but these relations have to exist one way or another in machine readable format. More the connections are documented, the better.)</li>
<li>Working with annotations should be relatively rapid and effortless</li>
</ul>
<p>In reality one has to balance between these principles. Of course one could argue that the last one is easiest to cut from, but the case is not so straightforward, as it has direct impact to the working hours spent which eventually comes into the number of occurrences in the corpus. This is especially important if more statistical methods are employed, for which it may be reasonable to have several parallel datasets used for testing different hypotheses. If data editing is extremely tedious, then it becomes much less feasible that the data is treated as would be the most suitable. And all this kind of boils down to the fact:</p>
<ul>
<li>There has to be a long-term data curation plan where these study-specific annotations fit</li>
</ul>
<p>Even though some annotations would be done just for one study, there is no reason they should be separated from the rest of the corpus. However, they should be added to the corpus in a way which doesn’t demand extra work from normal data curation. This means that they should not be too fixed to the current values, for example, they should not assume that elements such as tokens are immutable.</p>
</div>
<div id="reproducibility" class="section level2">
<h2><span class="header-section-number">3.3</span> Reproducibility</h2>
<p>By saying that my study is reproduceable I do not claim that my results are necessarily correct. I only mean that the others can verify what I have done and evaluate it with the data I have used. Ideally the study results would be repeated with a different dataset, which would in many ways be actually desired, since that would immediately add credibility to my ideas presented here. As reproducibility is a rather new concept in linguistic sciences, there seems to be quite a bit of confusion over the terms <strong>reproduction</strong>, <strong>replication</strong> and <strong>independent verification</strong>. Biostatistician Roger Peng has written very clearly about this in <a href="http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/">Simply Statistics blog</a> <span class="citation">(Peng <a href="#ref-peng2014a">2014</a>)</span>.</p>
<p>The study follows logic not particularly unusual for a scientific study: a phenomena has been observed and found interesting after further contextualization. A further study was planned in order to find out what it is about, so a corpus sample has been selected and annotated. These annotations are analyzed and the results are interpreted against the ideas that arose after the initial observation and contextualisation. The analysis part is mainly within the <a href="conclusions.html#conclusions">4</a> Conclusions section of this study.</p>
</div>
<div id="archiving" class="section level2">
<h2><span class="header-section-number">3.4</span> Archiving</h2>
<p>The corpus files are archived in The Language Archive of Nijmegen Max Planck institute. They are organized under the node <strong>Permic_Varieties/kpv/</strong>. In the archive structure all sessions are treated as entities on same hierarchy level. This may seem confusing, but the idea is that one has to consult metadata in order to know into which project and working group which session is connected. It would had been customary to organize data by <strong>academic projects</strong>. However, this model becomes problematic when the same data has been collected, transcribed, digitalized, reanalyzed and archived by totally disconnected people often many decades apart from one another. Thereby the only model to arrange these files in an honest manner is to list in metadata all relevant actors and projects involved.</p>
<p>In the archive there has been an attempt to maintain rough dialect division, so that the files would be named by prefixes marking different varieties. This is also complicated topic, as same recording contains often data from speakers of different dialects. Individual speakers have often been very mobile, so they also can have mixed features in their everyday speech. As many other good ideas, also this dialect based file naming has been somewhat futile.</p>
<p>The subcorpus used in this study today, 2016-05-28, may not be connected to those files the archive contains in whatever future date this study is being read. However, this study refers explicitly to those file versions which were valid and accessible at the time when this document was compiled.</p>
</div>
<div id="ELAN-model" class="section level2">
<h2><span class="header-section-number">3.5</span> ELAN annotations</h2>
<p>The ELAN annotation model used in the corpus is relatively simple, the data being set on different layers which correspond to specific time-aligned utterances. This means that for one Komi utterance there are often different data layers, for example, Russian translation, English translation or comments. Also tokenized data layer is provided, but the tokenized units are not connected to the recording itself.</p>
<p>For this study a new layer is added on which the tokens containing sibilants are time aligned and transcribed in IPA. This has been done by copying the token containing tier, filtering out the tokens which do not contain palatal sibilants and time aligning the remaining word forms.</p>
<p>The steps taken have been:</p>
<ul>
<li>Copying tier of symbolic subdivision type which contains the tokens into tier of included in type</li>
<li>Filtering the sibilant containt forms with regular expression <code>^((?!зь)(?!зё)(?!зя)(?!зю)(?!зи)(?!зе)(?!сь)(?!сё)(?!ся)(?!сю)(?!си)(?!се)(?!Зь)(?!Зё)(?!Зя)(?!Зю)(?!Зи)(?!Зе)(?!Сь)(?!Сё)(?!Ся)(?!Сю)(?!Си)(?!Се)(?!тс)(?!ст)(?!Ст).)*$</code>, which selects everything that can’t contain a feature I am interested, and replacing it’s result with an empty string</li>
<li>Using ELAN’s <strong>Remove annotations or values</strong> tool to remove all annotations on this tier when they contain an empty annotation</li>
</ul>
<p>With this workflow we get from this:</p>
<div class="figure">
<img src="figures/elan1.png" alt="Elan file in the original state" />
<p class="caption">Elan file in the original state</p>
</div>
<p>To this, which can relatively easily be time aligned:</p>
<div class="figure">
<img src="figures/elan2.png" alt="Added sib-tier with only sibilants left" />
<p class="caption">Added sib-tier with only sibilants left</p>
</div>
<p>The transcription system used is described in section <a href="introduction.html#transcription-system">2.1</a>. about transcription systems.</p>
<p>This means that an utterance:</p>

<link rel="stylesheet" href="libs/leipzig.css">
        <div data-gloss style="border-top:0px solid; border-bottom:0px solid;">
                <p>пукав да сёй!</p>
                <p>Sit.down.IMP and eat.IMP</p>
                <p>Sit down and eat!</p>
                <!-- JavaScript -->
        </div>
        <script src="libs/leipzig.js"></script>
        <script>
                document.addEventListener('DOMContentLoaded', function() {
                Leipzig().gloss();
        });
</script>
<p>Would be transcribed on the sibilant annotation tier as:</p>
<blockquote>
<p>ɕoj or sʲoj</p>
</blockquote>
<p>This is not a perfect method, but the best I was able to come up within the rationale and limitations explained above.</p>
<p>Now there is still quite much manual work in translitteration to phonemic IPA, aligning everything and identifying the necessary phonetic adjustments. Thereby I wrote a small function which does the transliteration. The screenshot below illustrates the changes it does inside ELAN file:</p>
<div class="figure">
<img src="figures/elan_ipa_diff.png" alt="Sibilant tier before and after running sle2016partanen::sib_tier_cyr2ipa function" />
<p class="caption">Sibilant tier before and after running sle2016partanen::sib_tier_cyr2ipa function</p>
</div>
<p>After this each token on sibilant tier is manually aligned and evaluated. This is relatively time consuming phase, but in many ways it is also the most important one. The whole study is in the end about these variables, so spending most of the time with analysing them is indeed quite appropriate. What I’ve tried to reach in this workflow is state where minimal amount of time is spent in rather unimportant manual tasks, and thereby what really matters gets the time it deserves. In the end automated workflow also makes it possible to reach relatively large sample within the current time frame. Although time is not really the most pressing issue, our daily working hours are in the end always limited.</p>
<div id="caveouts-of-the-current-annotation-model" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Caveouts of the current annotation model</h3>
<p>The problem with the current model is that it is pretty manual and the annotated sibilant containing forms are not strictly connected to the corresponding tokens within the utterances. The main reason to this is that I want the sibilant annotated tokens to remain independent from further changes in the main transcription.</p>
<p>It is also somewhat problematic that the actual annotation is usually done in a longer time span and the exact method may be refined. For example, one may realize later a context which should had been taken into account in the regular expression. This leads to a change which is automatically implemented in the further files, but must be manually carried out in older files. This is not a huge problem in itself, but it means that the workflow is easily not as reproduceable and automatic as it may seem.</p>
</div>
</div>
<div id="automated-processing-with-r" class="section level2">
<h2><span class="header-section-number">3.6</span> Automated processing with R</h2>
<p>In order to retrieve the sibilant information from ELAN files an R package <code>FRelan</code> is used. It contains several functions for parsing data from ELAN files to a data frame, which is an R internal tabular format which works rather well for data like this. Each token forms its own row. This data frame is merged with metadata which contains biographical and geographical information about, for example, about the speakers themselves and the time and place related information about the context where the utterance was recorded.</p>
<p>The variables relevant for my analysis are:</p>
<ul>
<li>Age of the speaker</li>
<li>Birthplace of the speaker</li>
<li>Place of residence of the speaker</li>
<li>Recording time</li>
<li>Recording setting (formal, informal)</li>
<li>Education of the speaker</li>
</ul>
<p>These variables are compared to the frequency of different sibilant allophones.</p>
</div>
<div id="praat" class="section level2">
<h2><span class="header-section-number">3.7</span> Praat</h2>
<p>Most of the time the distinction between these allophones is relatively easy to hear. However, I have used Praat in many cases to establish the baseline for these features, and also to validate whether some cases are as complex as they sound like.</p>
</div>
<div id="statistical-analysis" class="section level2">
<h2><span class="header-section-number">3.8</span> Statistical analysis</h2>
<p>Statistical methods have not been widely employed within Uralic studies, although sociolinguistics has been practised in different forms. However, for whatever reasons variationistic studies have not been very common. Within wider perspective of sociolinguistics Sali Tagliamonte gives quite nice overview in her recent book <span class="citation">(<a href="#ref-tagliamonte2016a">2016</a>, 107)</span> about the history of statistical methods on this field. She refers to her interview with David Sankoff, with the observation that within sociolinguistics the data generally tends to be messier and more complicated than on many other scientific fields where statistical methods are regularly employed. Later the discussion turns into the fact how ultimately one has to be familiar with the dataset used, and I also However, inevitable conclusion is that one has to employ some statistical tools in order to verify, and also often to find, the patterns in the data.</p>

</div>
</div>
<h3><span class="header-section-number">6</span> References</h3>
<div id="refs" class="references">
<div id="ref-tagliamonte2006a">
<p>Tagliamonte, Sali A. 2006. <em>Analysing Sociolinguistic Variation</em>. Key Topics in Sociolinguistics. Cambridge University Press.</p>
</div>
<div id="ref-milroyEtAl1997a">
<p>Milroy, James, and Lesley Milroy. 1997. “Exploring the Social Constraints on Language Change: Essays in Memory of Einar Haugen.” In <em>Language and Its Ecology</em>, 75–101. Trends in Linguistics. Studies and Monographs 100. Mouton de Gruyter.</p>
</div>
<div id="ref-cypanov2009a">
<p>Tsypanov, Jevgeni. 2009. “Permiläisten Kielten Nykytila.” In <em>The Quasquicentennial of the Finno-Ugrian Society</em>, edited by Jussi Ylikoski, 207–44. Suomalais-Ugrilaisen Seuran Toimituksia 258. Helsinki: Suomalais-ugrilainen Seura.</p>
</div>
<div id="ref-campbell-l2016a">
<p>Campbell, Lyle. 2016. “Language Documentation and Historical Linguistics: Studies in Honor of Marianne Mithun.” In <em>Language Contact and Change in Americas</em>, edited by Andrea Berez-Kroeker, Diane M. Hinz, and Carmen Jany, 249–73. John Benjamins Publishing Company.</p>
</div>
<div id="ref-partanenEtAl2016a">
<p>Partanen, Niko, and Janne Saarikivi. 2016. “Fragmentation of the Karelian Language and Its Community: Growing Variation at the Threshold of Language Shift: New and Old Language Diversities.” In <em>Linguistic Genocide or Superdiversity</em>, edited by Reetta Toivanen and Janne Saarikivi, 0–0. Multilingual Matters.</p>
</div>
<div id="ref-paunonen2000a">
<p>Paunonen, Heikki. 2000. “Suomen Kielen Morfologisista Muutosmekanismeista.” In <em>Muotojen Mieli. Kirjoituksia Morfologiasta Ja Variaatiosta</em>, edited by Lea Laitinen, Hanna Lappalainen, Päivi Markkola, and Johanna Vaattovaara, 187–248. Kieli 5. Helsingin yliopiston suomen kielen laitos.</p>
</div>
<div id="ref-nagyEtAl2015a">
<p>Nagy, Naomi, and Miriam Meyerhoff. 2015. “Extending ELAN into Quantitative Sociolinguistics.” <em>Linguistics Vanguard</em> 1 (1): 271–81.</p>
</div>
<div id="ref-peng2014a">
<p>Peng, Roger. 2014. “The Real Reason Reproducible Research Is Important.” <a href="http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/" class="uri">http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/</a>.</p>
</div>
<div id="ref-tagliamonte2016a">
<p>Tagliamonte, Sali A. 2016. <em>Making Waves: The Story of Variationist Sociolinguistics</em>. Wiley Blackwell.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusions.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/nikopartanen/sle2016partanenblob/master/02-methodology.rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
